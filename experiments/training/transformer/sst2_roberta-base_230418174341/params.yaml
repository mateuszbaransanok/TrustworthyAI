seed: 2024
task_name: transformer
training_name: sst2_roberta-base_230418174341
data_name: sst2
data_config:
  tokenizer_name: roberta-base
  batch_size: 16
  num_workers: 6
  max_length: 384
  dataset_name: sst2
model_name: roberta-base
model_config:
  model_name: roberta-base
  optimizer_name: adam
  learning_rate: 2.0e-05
  weight_decay: 0.01
  num_warmup_steps: 1000
trainer:
  max_epochs: 100
  gpu:
  - 0
